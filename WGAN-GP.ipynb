{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUY_N9u6kF_9"
      },
      "outputs": [],
      "source": [
        "# Using EM distance in practice for GANs\n",
        "# Gradient penalty\n",
        "# Implementing WGAN-GP to train the DCGAN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPIdw_oKirU_",
        "outputId": "599f38be-2be3-40a3-f4c8-c6a2f9fb8a01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcnHxPxXirgP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.autograd import grad as torch_grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Feu5A2oKl5FL",
        "outputId": "6af4831d-25a7-4b54-984d-cabbe19098fc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 5.49MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 160kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.51MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.75MB/s]\n"
          ]
        }
      ],
      "source": [
        "# data.py\n",
        "torch.manual_seed(1)\n",
        "np.random.seed(1)\n",
        "\n",
        "image_path = \"./\"\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.5), std=(0.5)),\n",
        "])\n",
        "mnist_dataset = torchvision.datasets.MNIST(root=image_path,\n",
        "                                           train=True,\n",
        "                                           transform=transform,\n",
        "                                           download=True)\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "mnist_dl = DataLoader(mnist_dataset, batch_size=batch_size,\n",
        "                      shuffle=True, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yo0a2JQygPgl"
      },
      "outputs": [],
      "source": [
        "def make_generator_network_wgan(input_size, n_filters):\n",
        "    model = nn.Sequential(\n",
        "        nn.ConvTranspose2d(input_size, n_filters*4, 4, 1, 0,\n",
        "                           bias=False),\n",
        "        nn.InstanceNorm2d(n_filters*4),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.ConvTranspose2d(n_filters*4, n_filters*2, 3, 2, 1, bias=False),\n",
        "        nn.InstanceNorm2d(n_filters*2),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.ConvTranspose2d(n_filters*2, n_filters, 4, 2, 1, bias=False),\n",
        "        nn.InstanceNorm2d(n_filters),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.ConvTranspose2d(n_filters, 1, 4, 2, 1, bias=False),\n",
        "        nn.Tanh())\n",
        "    return model\n",
        "\n",
        "class DiscriminatorWGAN(nn.Module):\n",
        "    def __init__(self, n_filters):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Conv2d(1, n_filters, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(n_filters, n_filters*2, 4, 2, 1, bias=False),\n",
        "            nn.InstanceNorm2d(n_filters * 2),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(n_filters*2, n_filters*4, 3, 2, 1, bias=False),\n",
        "            nn.InstanceNorm2d(n_filters*4),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(n_filters*4, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.network(input)\n",
        "        return output.view(-1, 1).squeeze(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCwW8lR1ip9G"
      },
      "outputs": [],
      "source": [
        "gen_model = make_generator_network_wgan(z_size, n_filters).to(device)\n",
        "disc_model = DiscriminatorWGAN(n_filters).to(device)\n",
        "\n",
        "g_optimizer = torch.optim.Adam(gen_model.parameters(), 0.0002)\n",
        "d_optimizer = torch.optim.Adam(disc_model.parameters(), 0.0002)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phtPlI_ejQVI"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "mode_z = \"uniform\"\n",
        "z_size = 100\n",
        "image_size = (28, 28)\n",
        "n_filters = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ci6JxPJAmKCx"
      },
      "outputs": [],
      "source": [
        "def create_noise(batch_size, z_size, mode_z):\n",
        "    if mode_z == \"uniform\":\n",
        "        input_z = torch.rand(batch_size, z_size, 1, 1)*2 - 1\n",
        "    elif mode_z == \"normal\":\n",
        "        input_z = torch.randn(batch_size, z_size, 1, 1)\n",
        "    return input_z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGJ4heigjqK-"
      },
      "outputs": [],
      "source": [
        "# function to compute the GP component\n",
        "\n",
        "def gradient_penalty(real_data, generated_data):\n",
        "    batch_size = real_data.size(0)\n",
        "\n",
        "    # Calculate interpolation\n",
        "    alpha = torch.rand(real_data.shape[0], 1, 1, 1, requires_grad=True, device=device)\n",
        "    interpolated = alpha * real_data + (1 - alpha) * generated_data\n",
        "\n",
        "    # Calculate probability of interpolated examples\n",
        "    proba_interpolated = disc_model(interpolated)\n",
        "\n",
        "    # Calculate gradients of probabilities with respect to examples\n",
        "    gradients = torch_grad(outputs=proba_interpolated, inputs=interpolated,\n",
        "                           grad_outputs=torch.ones(proba_interpolated.size(), device=device),\n",
        "                           create_graph=True, retain_graph=True)[0]\n",
        "\n",
        "    gradients = gradients.view(batch_size, -1)\n",
        "    gradients_norm = gradients.norm(2, dim=1)\n",
        "    return lambda_gp * ((gradients_norm - 1)**2).mean()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAAukPBTk-go"
      },
      "outputs": [],
      "source": [
        "## Train the discriminator\n",
        "def d_train_wgan(x):\n",
        "    disc_model.zero_grad()\n",
        "\n",
        "    batch_size = x.size(0)\n",
        "    x = x.to(device)\n",
        "\n",
        "    # Calculate probabilities on real and generated data\n",
        "    d_real = disc_model(x)\n",
        "    input_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
        "    g_output = gen_model(input_z)\n",
        "    d_generated = disc_model(g_output)\n",
        "    d_loss = d_generated.mean() - d_real.mean() + gradient_penalty(x.data, g_output.data)\n",
        "    d_loss.backward()\n",
        "    d_optimizer.step()\n",
        "\n",
        "    return d_loss.data.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjNxrYWQlqQo"
      },
      "outputs": [],
      "source": [
        "## Train the generator\n",
        "def g_train_wgan(x):\n",
        "    gen_model.zero_grad()\n",
        "\n",
        "    batch_size = x.size(0)\n",
        "    input_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
        "    g_output = gen_model(input_z)\n",
        "\n",
        "    d_generated = disc_model(g_output)\n",
        "    g_loss = -d_generated.mean()\n",
        "\n",
        "    # gradient backprop & optimize ONLY G's parameters\n",
        "    g_loss.backward()\n",
        "    g_optimizer.step()\n",
        "\n",
        "    return g_loss.data.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "XR9p4lLFmTOP",
        "outputId": "76e14b11-1cc3-459d-9ca4-3ad425399aab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 001 | D Loss >> -0.3422\n",
            "Epoch 002 | D Loss >> -0.5140\n",
            "Epoch 003 | D Loss >> -0.5478\n",
            "Epoch 004 | D Loss >> -0.5194\n"
          ]
        }
      ],
      "source": [
        "epoch_samples_wgan = []\n",
        "lambda_gp = 10.0\n",
        "num_epochs = 100\n",
        "torch.manual_seed(1)\n",
        "critic_iterations = 5\n",
        "\n",
        "fixed_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
        "\n",
        "def create_samples(g_model, input_z):\n",
        "    g_output = g_model(input_z)\n",
        "    images = torch.reshape(g_output, (batch_size, *image_size))\n",
        "    return (images+1)/2.0\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    gen_model.train()\n",
        "    d_losses, g_losses = [], []\n",
        "    for i, (x, _) in enumerate(mnist_dl):\n",
        "        for _ in range(critic_iterations):\n",
        "            d_loss = d_train_wgan(x)\n",
        "        d_losses.append(d_loss)\n",
        "        g_losses.append(g_train_wgan(x))\n",
        "\n",
        "    print(f'Epoch {epoch:03d} | D Loss >>'\n",
        "          f' {torch.FloatTensor(d_losses).mean():.4f}')\n",
        "    gen_model.eval()\n",
        "    epoch_samples_wgan.append(\n",
        "        create_samples(gen_model, fixed_z).detach().cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qh6yG9OKmsis"
      },
      "outputs": [],
      "source": [
        "selected_epochs = [1, 2, 4, 10, 50, 100]\n",
        "# selected_epochs = [1, 10, 20, 30, 50, 70]\n",
        "fig = plt.figure(figsize=(10, 14))\n",
        "for i,e in enumerate(selected_epochs):\n",
        "    for j in range(5):\n",
        "        ax = fig.add_subplot(6, 5, i*5+j+1)\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "        if j == 0:\n",
        "            ax.text(\n",
        "                -0.06, 0.5, f'Epoch {e}',\n",
        "                rotation=90, size=18, color='red',\n",
        "                horizontalalignment='right',\n",
        "                verticalalignment='center',\n",
        "                transform=ax.transAxes)\n",
        "\n",
        "        image = epoch_samples_wgan[e-1][j]\n",
        "        ax.imshow(image, cmap='gray_r')\n",
        "\n",
        "plt.savefig(\"/content/drive/MyDrive/GANs/WGAN_GP/sample_plot.png\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHfcuDrtoulP"
      },
      "outputs": [],
      "source": [
        "# saving\n",
        "torch.save(gen_model.state_dict(), \"/content/drive/MyDrive/GANs/WGAN_GP/generator_model.pth\")\n",
        "torch.save(disc_model.state_dict(), \"/content/drive/MyDrive/GANs/WGAN_GP/discriminator_model.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fgku7520v5xl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}